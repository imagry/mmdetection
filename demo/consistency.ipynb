{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2854a83-ae31-47c8-a3c6-149f3c8fc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def crop_image(filename, x, y, w, h, out_dir='/opt/imagry/Downloads/crops'):\n",
    "    basename = os.path.basename(filename)\n",
    "    prefix, ext = os.path.splitext(basename)\n",
    "    img = np.array(Image.open(filename))\n",
    "    cropped_img = img[y:y+h, x:x+w, :]\n",
    "    cropped_img = Image.fromarray(cropped_img)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f'{prefix}_{x}_{y}_{w}_{h}{ext}')\n",
    "    print(out_path)\n",
    "    cropped_img.save(out_path)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae54d93-d413-4b58-abd4-ae24fe54f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models is a list of model names, and them will print automatically\n",
    "models = DetInferencer.list_models('mmdet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ac9b7-7e74-4599-8921-b3c14e64a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mmdet.evaluation import CocoMetric\n",
    "from mmdet.apis import DetInferencer\n",
    "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco')\n",
    "import torch\n",
    "dataset_meta = inferencer.model.__dict__['dataset_meta']\n",
    "def process_result(result, to_tensor=True):\n",
    "    result = result['predictions'][0]\n",
    "    if to_tensor:\n",
    "        for k in ['bboxes', 'scores', 'labels']:\n",
    "            result[k] = torch.tensor(result[k])\n",
    "    return result\n",
    "\n",
    "def processed_result_to_annotation(result):\n",
    "    anns = []\n",
    "    for i in range(len(result['labels'])):\n",
    "        if not isinstance(result['bboxes'][i], list):\n",
    "            bbox = list((result['bboxes'][i].cpu().numpy()))\n",
    "        else:\n",
    "            bbox = result['bboxes'][i]\n",
    "                    \n",
    "        anns.append(dict(bbox_label=result['labels'][i], bbox=bbox))\n",
    "    return anns\n",
    "    \n",
    "def get_results(model, img_paths, out_dir, device='cuda:0'):\n",
    "    inferencer = DetInferencer(model, device=device)\n",
    "    results = []\n",
    "    for img_path in img_paths:\n",
    "        results.append(inferencer(img_path, out_dir=out_dir))\n",
    "    del inferencer\n",
    "    torch.cuda.empty_cache()\n",
    "    return results\n",
    "    \n",
    "def compute_confusion(model_a, model_b, img_paths, out_dir_a, out_dir_b, metric='coco/bbox_mAP'):\n",
    "    confusion = []\n",
    "    results_a = get_results(model_a, img_paths, out_dir_a)\n",
    "    results_b = get_results(model_b, img_paths, out_dir_b)\n",
    "\n",
    "    for i in range(len(results_a)):\n",
    "        results_a_ = process_result(results_a[i])\n",
    "        results_b_ = process_result(results_b[i], to_tensor=False)\n",
    "        coco_metric = CocoMetric(ann_file= None, metric=['bbox'], classwise=True, outfile_prefix='/opt/imagry/Downloads/confusion')\n",
    "        coco_metric.dataset_meta = dataset_meta\n",
    "        coco_metric.process({}, [\n",
    "            dict(\n",
    "                pred_instances=results_a_,\n",
    "                img_id=0,\n",
    "                ori_shape=(1920, 1080),\n",
    "                instances=processed_result_to_annotation(results_b_))\n",
    "        ])\n",
    "        eval_results = coco_metric.evaluate(size=1)\n",
    "        confusion.append((img_paths[i], eval_results[metric]))\n",
    "    return confusion, eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1be444-90d6-4531-be7f-204902be62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_folder = '/home/imagry/Downloads/2024-03-12T09_16_53/3d_images/0/left'\n",
    "img_paths = os.listdir(img_folder)\n",
    "img_paths = [os.path.join(img_folder, p) for p in img_paths]\n",
    "confusion, eval_results = compute_confusion('mask-rcnn_r50_fpn_dconv_c3-c5_1x_coco', 'mask-rcnn_r101-dconv-c3-c5_fpn_1x_coco', img_paths, 'outputs_a/', 'outputs_b/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c091359-6e2f-49d3-8173-c7de215410c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def visualize(confusion, folder, folder_a, folder_b, case, output_folder='/opt/imagry/Downloads/confusion'):\n",
    "    os.makedirs(os.path.join(output_folder, case), exist_ok=True)\n",
    "    for fn, c in confusion:\n",
    "        print(fn, c)\n",
    "        basename = os.path.basename(fn)\n",
    "        im = Image.open(os.path.join(folder, basename))\n",
    "        im_a = Image.open(os.path.join(folder_a, basename))\n",
    "        im_b = Image.open(os.path.join(folder_b, basename))\n",
    "\n",
    "        Image.fromarray(np.hstack((np.array(im), np.array(im_a), np.array(im_b)))).save(os.path.join(output_folder, case, basename))      \n",
    "N=100\n",
    "\n",
    "confusion.sort(key = lambda x: x[1])\n",
    "\n",
    "best_images = confusion[-N:]\n",
    "worst_images = confusion[:N]\n",
    "\n",
    "print('.....Best Images......')\n",
    "visualize(best_images, img_folder, './outputs_a/vis', './outputs_b/vis', 'best')\n",
    "\n",
    "print('.....Worst Images......')\n",
    "visualize(worst_images, img_folder, './outputs_a/vis', './outputs_b/vis', 'worst')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
